{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym Taxi-v2 environment\n",
    "\n",
    "> lets have a look at the problem and how the env has been setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-04 13:06:34,933] Making new env: Taxi-v2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()   # init state value of env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.n   # number of possible values in this state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n   # number of possible actions\n",
    "# print(env.action_space)\n",
    "# 0 = down\n",
    "# 1 = up\n",
    "# 2 = right\n",
    "# 3 = left\n",
    "# 4 = pickup\n",
    "# 5 = drop-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()\n",
    "# In this environment the yellow square represents the taxi, the (“|”) represents a wall, the blue letter represents the pick-up location, and the purple letter is the drop-off location. The taxi will turn green when it has a passenger aboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.env.s = 114\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[43mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is considered solved when you successfully pick up a passenger and drop them off at their desired location. Upon doing this, you will receive a reward of 20 and done will equal True.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first naive solution \n",
    "\n",
    "> at every step, randomly choose one of the available 6 actions\n",
    "\n",
    "A core part of evaluating any agent's performance is to compare it against a completely random agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxiRandomSearch(env):\n",
    "    \"\"\" Randomly pick an action and keep guessing until the env is solved\n",
    "    :param env: Gym Taxi-v2 env\n",
    "    :return: number of steps required to solve the Gym Taxi-v2 env\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    stepCounter = 0\n",
    "    reward = None\n",
    "    while reward != 20:  # reward 20 means that the env has been solved\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        stepCounter += 1\n",
    "    return stepCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2430\n"
     ]
    }
   ],
   "source": [
    "print(taxiRandomSearch(env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build in some memory to remember actions and their associated rewards\n",
    "\n",
    "- the memory is going to be a Q action value table (using a np array of size 500x6, nb of states x nb of actions)\n",
    "\n",
    "In short, the problem is solved multiple times (each time called an *episode*) and the Q-table (memory) is updated to improve the algorithm's efficiency and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n])   # memory, stores the value (reward) for every single state and every action you can take\n",
    "G = 0   # accumulated reward for each episode\n",
    "alpha = 0.618   # learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def taxiQlearning(env):\n",
    "    \"\"\" basic Q learning algo\n",
    "    :param env: Gym Taxi-v2 env\n",
    "    :return: None\n",
    "    \"\"\"    \n",
    "    for episode in range(1,1001):\n",
    "        stepCounter = 0\n",
    "        done = False\n",
    "        G, reward = 0,0\n",
    "        state = env.reset()\n",
    "        while done != True:\n",
    "            action = np.argmax(Q[state]) # 1: find action with highest value/reward at the given state\n",
    "            state2, reward, done, info = env.step(action) # 2: take that 'best action' and store the future state\n",
    "            Q[state,action] += alpha * (reward + np.max(Q[state2]) - Q[state,action]) # 3: update the q-value using Bellman equation\n",
    "            G += reward\n",
    "            state = state2    \n",
    "            stepCounter += 1\n",
    "        if episode % 50 == 0:\n",
    "            print('Episode {} Total Reward: {}'.format(episode,G))    \n",
    "            print('Steps required for this episode: %i'% stepCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 Total Reward: 5\n",
      "Steps required for this episode: 16\n",
      "Episode 100 Total Reward: -40\n",
      "Steps required for this episode: 61\n",
      "Episode 150 Total Reward: -47\n",
      "Steps required for this episode: 68\n",
      "Episode 200 Total Reward: 13\n",
      "Steps required for this episode: 8\n",
      "Episode 250 Total Reward: 14\n",
      "Steps required for this episode: 7\n",
      "Episode 300 Total Reward: 7\n",
      "Steps required for this episode: 14\n",
      "Episode 350 Total Reward: 6\n",
      "Steps required for this episode: 15\n",
      "Episode 400 Total Reward: 9\n",
      "Steps required for this episode: 12\n",
      "Episode 450 Total Reward: 9\n",
      "Steps required for this episode: 12\n",
      "Episode 500 Total Reward: 7\n",
      "Steps required for this episode: 14\n",
      "Episode 550 Total Reward: 9\n",
      "Steps required for this episode: 12\n",
      "Episode 600 Total Reward: 10\n",
      "Steps required for this episode: 11\n",
      "Episode 650 Total Reward: 4\n",
      "Steps required for this episode: 17\n",
      "Episode 700 Total Reward: 9\n",
      "Steps required for this episode: 12\n",
      "Episode 750 Total Reward: 9\n",
      "Steps required for this episode: 12\n",
      "Episode 800 Total Reward: 8\n",
      "Steps required for this episode: 13\n",
      "Episode 850 Total Reward: 10\n",
      "Steps required for this episode: 11\n",
      "Episode 900 Total Reward: 9\n",
      "Steps required for this episode: 12\n",
      "Episode 950 Total Reward: 6\n",
      "Steps required for this episode: 15\n",
      "Episode 1000 Total Reward: 10\n",
      "Steps required for this episode: 11\n"
     ]
    }
   ],
   "source": [
    "taxiQlearning(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 787.81767312   -9.27         -8.74731466   -9.27        -12.36        -12.36      ]\n"
     ]
    }
   ],
   "source": [
    "print(Q[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
